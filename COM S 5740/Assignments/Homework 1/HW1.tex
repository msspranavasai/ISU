\documentclass[11pt]{article}

% Use Helvetica font.
%\usepackage{helvet}

%\usepackage[T1]{fontenc}
%\usepackage[sc]{mathpazo}
\usepackage{color}
\usepackage{amsmath,amsthm,amssymb,multirow,paralist}
%\renewcommand{\familydefault}{\sfdefault}

% Use 1/2-inch margins.
\usepackage[margin=0.8in]{geometry}
\usepackage{hyperref}

\begin{document}

\begin{center}
{\Large \textbf{COM S 474/574: Introduction to Machine Learning}

Homework \#1}\\

\linethickness{1mm}\line(1,0){498}

\begin{enumerate}
\item Please put required code files and report into a
compressed file ``HW\#\_FirstName\_LastName.zip''
\item Unlimited number of submissions are
allowed on Canvas and the latest one will be graded.
\item {\color{red} No later submission is accepted.}
\item Please read and follow submission instructions. No exception
will be made to accommodate incorrectly submitted files/reports.
\item All students are required to typeset their reports using
latex. Overleaf
(\url{https://www.overleaf.com/learn/latex/Tutorials}) can be a
good start.
\end{enumerate}

\linethickness{1mm}\line(1,0){498}

\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{enumerate}
\item (10 points) Consider the perceptron in two dimensions:
$h(\boldsymbol x) = \mbox{sign}(\boldsymbol w^T \boldsymbol x)$
where $\boldsymbol w = [w_0, w_1, w_2]^T$ and $\boldsymbol x =
[1, x_1, x_2]^T$. Technically, $\boldsymbol x$ has three
coordinates, but we call this perceptron two-dimensional because
the first coordinate is fixed at 1.

\begin{enumerate}
    \item Show that the regions on the plane where $h(\boldsymbol
    x) = +1$ and $h(\boldsymbol x) = -1$ are separated by a line.
    If we express this line by the equation $x_2 = ax_1 + b$,
    what are the slope $a$ and intercept $b$ in terms of $w_0, w_1,
    w_2$?
    \item Draw pictures for the cases $\boldsymbol w=[1,2,3]^T$
    and $\boldsymbol w=-[1,2,3]^T$. Label the positive and negative
    prediction regions on the pictures.
\end{enumerate}

\item (30 points) In logistic regression (labels are \{1, -1\}),
the objective function  can be written as
$$E(w)=\frac{1}{N}\sum_{n=1}^N\ln\left(1+e^{-y_n
w^Tx_n}\right).$$ Please
\begin{enumerate}
\item (10 points) Compute the first-order derivative $\nabla E(w)$. You will
need to provide the intermediate steps of derivation.
\item (10 points) Once the optimal $w$ is obtain, it will be used to make
predictions as follows:
\[ \mbox{Predicted class of }x =
  \begin{cases}
    1       & \quad \text{if } \theta(w^Tx)\geq 0.5\\
    -1  & \quad \text{if } \theta(w^Tx)<0.5\\
  \end{cases}
\]
where $\theta(z)=\frac{1}{1+e^{-z}}$.

Explain why the decision boundary of logistic regression is still
linear, though the linear signal $w^Tx$ is passed through a
nonlinear function $\theta$ to compute the outcome of prediction.
\item (5 points) Is the decision boundary still linear if the prediction rule
is changed to the following? Justify briefly.
\[ \mbox{Predicted class of }x =
  \begin{cases}
    1       & \quad \text{if } \theta(w^Tx)\geq 0.9\\
    -1  & \quad \text{if } \theta(w^Tx)<0.9\\
  \end{cases}
\]
\item (5 points) In light of your answers to the above two questions, what is
the essential property of logistic regression that results in the
linear decision boundary?

\end{enumerate}

\item (10 points) Given

$$X=[x_1,x_2,\cdots,x_n]\in\mathbb{R}^{m\times n}$$
where
$x_i\in\mathbb{R}^m$ for all $i$, and
$$Y=\begin{bmatrix}
    y_1^T       \\
    y_2^T       \\
    \vdots\\
    y_n^T
\end{bmatrix}\in\mathbb{R}^{n\times p}$$
where $y_i\in\mathbb{R}^p$ for all $i$. Show that $$XY=\sum_{i=1}^n
x_i y_i^T.$$

\item (10 points) We show that maximizing log-likelihood is
equivalent to minimizing $RSS(\boldsymbol w)$.

In particular,
$$\log\mathcal{L}(\boldsymbol{w} | \boldsymbol{x})Â 
= -\frac{1}{2}\left( \frac{1}{\sigma^2}RSS(\boldsymbol{w}) + n \log \sigma^2 \right) + const$$
\begin{enumerate}
    \item (5 points) Please derive the optimal $\boldsymbol w^*$ and $\sigma^*$.
    \item (5 points) What do you observe from the optimal $\sigma^*$?
\end{enumerate}

\item (10 points) Show that sigmoid function and
softmax function are the same in the binary case.
\begin{align*}
    &\mbox{sigmoid}(y) = \frac{1}{1 + e^{-y}}\\
    &\mbox{softmax}(y_j) = \frac{e^{y_j}}{\sum_{i=1}^c e^{y_i}} 
\end{align*}

\item (30 points) \textbf{Perceptron for Handwritten Digits Recognition}:
The handwritten digits files are in the ``data'' folder: train.txt
and test.txt. The starting code is in the ``code'' folder. In the
data file, each row is a data example. The first entry is the digit
label (``1'' or ``5''), and the next 256 are grayscale values
between -1 and 1. The 256 pixels correspond to a $16\times16$ image.
You are expected to implement your solution based on the given
codes. The only file you need to modify is the ``solution.py'' file.
You can test your solution by running ``main.py" file. Note that
code is provided to compute a two-dimensional feature (symmetry and
average intensity) from each digit image; that is, each digit image
is represented by a two-dimensional vector before being augmented
with a ``1'' to form a three-dimensional vector as discussed in
class. These features along with the corresponding labels should
serve as inputs to your Perceptron algorithm.
{\color{red}You are expected to use Python3.}

\begin{enumerate}
\item (5 points) Familiarize yourself with the data by completing the \emph{show\_images} function. Include the images you plotted in your report.
\item (5 points) In this assignment, we have already extracted two features, symmetry and
average intensity, to distinguish between 1 and 5. Familiarize
yourself with the features by completing the \emph{show\_features}
function and include the 2-D scatter plot into your report. For each
sample, plot the two features with a red \textcolor{red}{$*$} if the
label is 1 and a blue \textcolor{blue}{$+$}  if the label is 5.
\item (10 points) Complete the \emph{Perceptron} class. You can test your
accuracy results using the ``test\_accuracy'' function in
``main.py''.
\item (10 points) Complete the \emph{show\_result} function to plot the
test data with the separators. Include the images you plotted into
your report.
\end{enumerate}

\textbf{Deliverable:} You should submit (1) a report
(along with your write-up for other questions) that summarizes your
results and (2) the ``solution.py'' file to the Canvas.

\textbf{Note:} Please read the ``Readme.txt'' file carefully before
you start this assignment. Please do {\color{red} NOT} change anything in the
``main.py'' and ``helper.py'' files when you program.

\end{enumerate}



\end{document}
